---
# Temporarily not in use, as it requires too many resources (3.5GB RAM)
- name: Check if Ollama container is running
  docker_container_info:
    name: ollama
  register: ollama_container_info

- name: Check if Ollama data directory exists
  stat:
    path: "{{ ollama_data_dir }}"
  register: ollama_data_dir_stat

- name: Create Ollama data directory
  file:
    path: "{{ ollama_data_dir }}"
    state: directory
    mode: '0755'
  when: not ollama_data_dir_stat.stat.exists

- name: Run Ollama Docker container
  docker_container:
    name: ollama
    image: "ollama/ollama:latest"
    state: started
    restart_policy: always
    ports:
      - "11434:11434"
    volumes:
      - "{{ ollama_data_dir }}:/root/.ollama"
  when: ollama_container_info.exists == false

- name: Wait for Ollama service to be ready
  wait_for:
    port: 11434
    timeout: 30

- name: Check if llama3.2 model exists
  community.docker.docker_container_exec:
    container: ollama
    command: ollama list
  register: model_check

- name: Pull llama3.2 model
  community.docker.docker_container_exec:
    container: ollama
    command: ollama run llama3.2
  when: "'llama3.2' not in model_check.stdout"
